---
title: "Exploratory Analysis"
author: "Tessa Senders"
date: "12/11/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load libraries, warning=FALSE, message=FALSE}
library(tidyverse)
library(stringr)
library(leaps)
library(car)
library(caret)
```

Import Data

```{r load data}
hate_crimes_df <- read.csv("./data/HateCrimes.csv") %>%
  janitor::clean_names() %>%
  rename(perc_pop_hs = perc_population_with_high_school_degree) %>% 
  mutate(hate_crimes_per_100k_splc = as.numeric(hate_crimes_per_100k_splc)) %>%
  drop_na(hate_crimes_per_100k_splc) %>%
  mutate(unemployment = as_factor(unemployment),
         urbanization = as_factor(urbanization))
```

4 Missing states (Hawaii, North Dakota, South Dakota, Wyoming)
Percent Non Citizen Maine is missing


Look at distribution of the outcome

```{r descriptive stats}
hate_crimes_df %>%
  ggplot(aes(x = hate_crimes_per_100k_splc)) +
  geom_histogram(aes(y=..density..)) +
  geom_density(alpha=.1, fill="#FF6666") + 
  labs(
    x = "Hate Crimes Per 100k",
    y = "Density",
    caption = "Figure 1: Untransformed distribution of hate crimes per 100k"
  )
```

Distribution of outcome after natural log transformation

```{r attempt transformation of outcome}
hate_crimes_df %>%
  mutate(hate_crimes_per_100k_splc = log(hate_crimes_per_100k_splc)) %>%
  ggplot(aes(x = hate_crimes_per_100k_splc)) +
  geom_density()
  
```


Add natural log transform to dataset

```{r add log transform}
hate_crimes_df <- hate_crimes_df %>%
  mutate(hate_crimes_log = log(hate_crimes_per_100k_splc))
```

Plot outcome in order by state

```{r box plot}
hate_crimes_df %>%
  mutate(state = fct_reorder(state, hate_crimes_log)) %>%
ggplot(aes(x = state, y = hate_crimes_log)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))
```

Remove any remaining missing data

```{r}
hate_crimes_df = hate_crimes_df %>%
  drop_na()
```


Regress given covariates (original model given by article)

```{r}
summary(lm(hate_crimes_per_100k_splc ~ . - state - hate_crimes_log, data = hate_crimes_df))
```

Yes, it does seem that the Gini index (income inequality) is the most significant predictor of hate crime and percent population with a HS degree is the only other significant predictor. Both of these results agree with the article.


Regress given covariates now on the transformed outcome (natural log)

```{r}
summary(lm(hate_crimes_log ~ . - state - hate_crimes_per_100k_splc, data = hate_crimes_df))
```

Here we re-ran the same model, but using log of the output. We obtain the same results in terms of significant variables. 


Modeling results for just gini index as variable and log hate crimes as outcome

```{r}
summary(lm(hate_crimes_log ~ gini_index, data = hate_crimes_df))
```

Research to pick other covariates to potentially include in our model.

Variables shown to be statistically significant in existent literature: 

- Race, religion, sexual orientation - Source: Study of Literature And Legislation on Hate Crime in America (147 page report for the US Justice Department) (https://www.ncjrs.gov/pdffiles1/nij/grants/210300.pdf)
- Urbanization/population density, economic considerations (median income, poverty level, job availability), cultural and education factors - Source: US FBI website (https://ucr.fbi.gov/hate-crime/2011/resources/variables-affecting-crime)
-Article supports percent non-white as an important variable (for college campuses): https://journals-sagepub-com.proxy.lib.umich.edu/doi/full/10.1177/1043986214536666?utm_source=summon&utm_medium=discovery-provider
-Anti-hispanic and religious hate crimes on the rise: https://apnews.com/article/hate-crimes-rise-fbi-data-ebbcadca8458aba96575da905650120d
- “Variables Affecting Crime.” FBI, FBI, 5 Nov. 2012, ucr.fbi.gov/hate-crime/2011/resources/variables-affecting-crime. 



Correlation matrix of all numeric variables with each other and calculate VIFs:

```{r cor mat}
# correlation matrix
hate_crimes_df %>% 
  drop_na(perc_non_citizen) %>%
  dplyr::select(!(state:urbanization)) %>% 
  cor() %>% 
  round(.,3) %>% knitr::kable()

#VIF
vif(lm(hate_crimes_log ~. - hate_crimes_per_100k_splc - state, data=hate_crimes_df)) %>%
  round(.,3) %>%
  knitr::kable()
```

Out of the continuous variables, percent non-citizen and percent non-white has a correlation coefficient of 0.753, median household income and percentage of population with a HS degree has a correlation coefficient of 0.651, both of which may suggest multi-collinearity. All other variables do not suggest multi-collinearity.


Drop either perc non citizen or per non white
Drop median household income due to multicollinearity with perc pop with HS degree




Backwards stepwise selection to come up with a preliminary model 

```{r model_stuff, message = FALSE, warning = FALSE}
# backwards selection

mult.fit <- lm(hate_crimes_log ~ . - state - hate_crimes_per_100k_splc, data = hate_crimes_df)
step(mult.fit, direction = 'backward')

## backwards selection found only gini index and hs education to be significant
bw_mod = lm(formula = hate_crimes_log ~ perc_pop_hs + gini_index, 
    data = hate_crimes_df)
summary(bw_mod)

##backwards selection pre-excluding pop hs...does it include median income???
mult.fit.2 <- lm(hate_crimes_log ~ . - state - hate_crimes_per_100k_splc -perc_pop_hs, data = hate_crimes_df)
step(mult.fit.2, direction = 'backward')

#Model with gini index and median household income
bw_mod_no_hs = lm(formula = hate_crimes_log ~ median_household_income + gini_index, 
    data = hate_crimes_df)
summary(bw_mod_no_hs)

#Model with median household income, perc pop hs, and gini index
summary(lm(formula = hate_crimes_log ~ median_household_income +perc_pop_hs + gini_index, 
    data = hate_crimes_df))
```


Forward selection to find alternative preliminary model

```{r, message = FALSE, warning = FALSE}
# forward selection

mult.fit <- lm(hate_crimes_log ~ . - state - hate_crimes_per_100k_splc, data = hate_crimes_df)
step(mult.fit, direction = 'forward')

## forward selection found urbanization, unemployment, income, percent hs education, percent non-citizen, percent non-white and gini index to be significant
fw_mod = lm(formula = hate_crimes_log ~ perc_pop_hs + gini_index + unemployment + urbanization + median_household_income + perc_non_citizen + perc_non_white, data = hate_crimes_df)
summary(fw_mod)
```

Test backwards stepwise selection models including multicollinearity

```{r, message = FALSE, warning = FALSE}
# multicollinearity stuff

#Model with perc non white and perc non citizen (and perc pop hs and gini index)
perc_race1 = lm(formula = hate_crimes_log ~ perc_pop_hs + gini_index + perc_non_white + perc_non_citizen, 
    data = hate_crimes_df)
summary(perc_race1)

#Model with just perc non citizen (and perc pop hs and gini index)
perc_race2 = lm(formula = hate_crimes_log ~ perc_pop_hs + gini_index + perc_non_citizen, 
    data = hate_crimes_df)
summary(perc_race2)

#Model with just perc non white (and perc pop hs and gini index)
perc_race3 = lm(formula = hate_crimes_log ~ perc_pop_hs + gini_index + perc_non_white, 
    data = hate_crimes_df)
summary(perc_race3)
```


Use Cp and Adjusted R^2 to find best models

```{r, message = FALSE, warning = FALSE}
# Printing the best models of each size, using the Cp criterion:
hc = hate_crimes_df %>%
  drop_na() %>%
  dplyr::select(-hate_crimes_per_100k_splc, -state) %>%
  mutate(unemployment = as.numeric(unemployment),
         urbanization = as.numeric(urbanization))

leaps::leaps(x = hc[,1:7], y = hc[,8], nbest=1, method="Cp")

# Printing the best models of each size, using the adjusted R squared criterion:

leaps::leaps(x = hc[,1:7], y = hc[,8], nbest=1, method="adjr2")

b <- regsubsets(hate_crimes_log ~ ., data=hc)
rs <- summary(b)
rs

par(mar=c(4,4,1,1))
par(mfrow=c(1,2))

plot(1:7, rs$cp, xlab="No of parameters", ylab="Cp Statistic")
abline(0,1)

plot(1:7, rs$adjr2, xlab="No of parameters", ylab="Adj R2")



# Summary of models for each size (one model per size)
# Function regsubsets() performs a subset slection by identifying the "best" model that contains a certain number of predictors. By default "best" is chosen using SSE/RSS (smaller is better).


hc_1 = hate_crimes_df %>%
  drop_na() %>%
  dplyr::select(-hate_crimes_per_100k_splc, -state) %>%
  mutate(unemployment = as.numeric(unemployment),
         urbanization = as.numeric(urbanization))

b_1 <- leaps::regsubsets(hate_crimes_log ~ ., data=hc_1, nvmax = 7)
summary(b_1)

res.sum_1 <- summary(b_1)
data.frame(
  Adj.R2 = which.max(res.sum_1$adjr2),
  CP = which.min(res.sum_1$cp),
  BIC = which.min(res.sum_1$bic)
)
```

Use ANOVA to compare the model with 2 covariates and the model with 3 covariates

```{r, message = FALSE, warning = FALSE}
# ANOVA
final_model <- lm(hate_crimes_log ~ gini_index + perc_pop_hs, data = hate_crimes_df )
summary(final_model)

final_model_unemploy <- lm(hate_crimes_log ~ gini_index + perc_pop_hs + unemployment, data = hate_crimes_df)
summary(final_model_unemploy)

anova(final_model, final_model_unemploy)

par(mfrow = c(2,2))
plot(final_model)
plot(final_model_unemploy)

```

DC is an outlier and there is evidence that it may be an influential point.


Test a model with interactions between each of the categorical variables and all the continuous variables-(pre-eliminate some continuous variables based on previous analysis).  Interaction between each categorical variable and the perc non white and perc non citizen

Interaction graphs of unemployment with all continuous variables:

```{r}
hate_crimes_df %>% pivot_longer(median_household_income:perc_non_white, names_to = "cont_var", values_to = "value") %>%  ggplot(aes(x = value, y = hate_crimes_log, color = unemployment)) + geom_point() + geom_smooth(method='lm', se=FALSE) + facet_wrap(~cont_var, scales = "free_x") 
hate_crimes_df_no_DC %>% pivot_longer(median_household_income:perc_non_white, names_to = "cont_var", values_to = "value") %>%  ggplot(aes(x = value, y = hate_crimes_log, color = unemployment)) + geom_point() + geom_smooth(method='lm', se=FALSE) + facet_wrap(~cont_var, scales = "free_x") 
```


Interaction graphs of urbanization with all continuous variables:

```{r}
hate_crimes_df %>% 
  pivot_longer(median_household_income:perc_non_white, names_to = "cont_var", values_to = "value") %>%  
  ggplot(aes(x = value, y = hate_crimes_log, color = urbanization)) +
  geom_point() + 
  geom_smooth(method='lm', se=FALSE) + 
  facet_wrap(~cont_var, scales = "free_x") 

hate_crimes_df_no_DC %>% 
  pivot_longer(median_household_income:perc_non_white, names_to = "cont_var", values_to = "value") %>%  
  ggplot(aes(x = value, y = hate_crimes_log, color = urbanization)) +
  geom_point() + 
  geom_smooth(method='lm', se=FALSE) + 
  facet_wrap(~cont_var, scales = "free_x")
```

Interaction models including DC

```{r, message = FALSE, warning = FALSE}}
# Interactions with DC

#Full model
full_mod = lm(hate_crimes_log ~ . - state - hate_crimes_per_100k_splc + unemployment*perc_pop_hs + unemployment*median_household_income + unemployment*perc_non_citizen + unemployment*gini_index + unemployment*perc_non_white + urbanization*perc_pop_hs + urbanization*median_household_income + urbanization*perc_non_citizen + urbanization*gini_index + urbanization*perc_non_white, data = hate_crimes_df)

summary(full_mod)

#Full model without median household income
full_mod_1 = lm(hate_crimes_log ~ . - state - hate_crimes_per_100k_splc + unemployment*perc_pop_hs + unemployment*perc_non_citizen + unemployment*gini_index + unemployment*perc_non_white + urbanization*perc_pop_hs + urbanization*perc_non_citizen + urbanization*gini_index + urbanization*perc_non_white, data = hate_crimes_df)

summary(full_mod_1)

#Our small model and unemployment
small_mod = lm(hate_crimes_log ~ gini_index + perc_pop_hs + gini_index*unemployment + perc_pop_hs*unemployment, data = hate_crimes_df)

summary(small_mod)

#Our small model and urbanization
small_mod_1 = lm(hate_crimes_log ~ gini_index + perc_pop_hs + gini_index*urbanization + perc_pop_hs*urbanization, data = hate_crimes_df)

summary(small_mod_1)

#Our small model and urbanization and unemployment
small_mod_2 = lm(hate_crimes_log ~ gini_index + perc_pop_hs + gini_index*urbanization + perc_pop_hs*urbanization+ gini_index*unemployment + perc_pop_hs*unemployment, data = hate_crimes_df)

summary(small_mod_2)

#Checking just interactions that appeared significant in the plot for unemployment:

plot_mod = lm(hate_crimes_log ~ median_household_income*unemployment, data = hate_crimes_df)
summary(plot_mod)

plot_mod_1 = lm(hate_crimes_log ~ perc_pop_hs*unemployment, data = hate_crimes_df)
summary(plot_mod_1)

#Checking just interactions that appeared significant in the plot for urbanization:

plot_mod_2 = lm(hate_crimes_log ~ gini_index*urbanization, data = hate_crimes_df)
summary(plot_mod_2)

plot_mod_3 = lm(hate_crimes_log ~ median_household_income*urbanization, data = hate_crimes_df)
summary(plot_mod_3)

plot_mod_4 = lm(hate_crimes_log ~ perc_non_citizen*urbanization, data = hate_crimes_df)
summary(plot_mod_4)

plot_mod_5 = lm(hate_crimes_log ~ perc_pop_hs*urbanization, data = hate_crimes_df)
summary(plot_mod_5)
```



Interaction models excluding DC

```{r DC code}
#No DC code and interactions
hate_crimes_df_no_DC <- hate_crimes_df %>%
  filter(state != "District of Columbia") %>%
  mutate(hate_crimes_log = log(hate_crimes_per_100k_splc))

hate_crimes_df = hate_crimes_df %>%
  mutate(hate_crimes_log = log(hate_crimes_per_100k_splc))

#All variables
mod = lm(hate_crimes_log ~ . - state - hate_crimes_per_100k_splc, data = hate_crimes_df_no_DC)
summary(mod)

#All interactions
full_mod = lm(hate_crimes_log ~ . - state - hate_crimes_per_100k_splc + unemployment*perc_pop_hs + unemployment*median_household_income + unemployment*perc_non_citizen + unemployment*gini_index + unemployment*perc_non_white + urbanization*perc_pop_hs + urbanization*median_household_income + urbanization*perc_non_citizen + urbanization*gini_index + urbanization*perc_non_white, data = hate_crimes_df_no_DC)

summary(full_mod)

#All interactions but removing median household income
full_mod_1 = lm(hate_crimes_log ~ . - state - hate_crimes_per_100k_splc + unemployment*perc_pop_hs + unemployment*perc_non_citizen + unemployment*gini_index + unemployment*perc_non_white + urbanization*perc_pop_hs + urbanization*perc_non_citizen + urbanization*gini_index + urbanization*perc_non_white, data = hate_crimes_df_no_DC)

summary(full_mod_1)

#Small model with unemployment interaction
small_mod = lm(hate_crimes_log ~ gini_index + perc_pop_hs + gini_index*unemployment + perc_pop_hs*unemployment, data = hate_crimes_df_no_DC)

summary(small_mod)

#Small model with urbanization interaction
small_mod_1 = lm(hate_crimes_log ~ gini_index + perc_pop_hs + gini_index*urbanization + perc_pop_hs*urbanization, data = hate_crimes_df_no_DC)

summary(small_mod_1)

#Small model and urbanization and unemployment
small_mod_2 = lm(hate_crimes_log ~ gini_index + perc_pop_hs + gini_index*urbanization + perc_pop_hs*urbanization+ gini_index*unemployment + perc_pop_hs*unemployment, data = hate_crimes_df_no_DC)

summary(small_mod_2)

#Checking just interactions that appeared significant in the plot for unemployment:

plot_mod = lm(hate_crimes_log ~ gini_index*unemployment, data = hate_crimes_df_no_DC)
summary(plot_mod)

plot_mod_1 = lm(hate_crimes_log ~ perc_pop_hs*unemployment, data = hate_crimes_df_no_DC)
summary(plot_mod_1)

#Checking just interactions that appeared significant in the plot for urbanization:

plot_mod_2 = lm(hate_crimes_log ~ median_household_income*urbanization, data = hate_crimes_df_no_DC)
summary(plot_mod_2)

plot_mod_3 = lm(hate_crimes_log ~ perc_pop_hs*urbanization, data = hate_crimes_df_no_DC)
summary(plot_mod_3)
```

There shows to be no significant interactions between either of the categorical variables and the continuous variables. Nor did removing median_household_income (because of multicollinearity) show any significant interactions. There also shows to be no interactions between either of the categorical variables and gini_index and perc_pop_hs in the smaller models. 


Now find if best models based on Cp and Adjusted R^2 change when DC is removed

```{r, message = FALSE, warning = FALSE}
# validation for no DC code
hc = hate_crimes_df_no_DC %>%
  drop_na() %>%
  dplyr::select(-hate_crimes_per_100k_splc, -state) %>%
  mutate(unemployment = as.numeric(unemployment),
         urbanization = as.numeric(urbanization))

leaps::leaps(x = hc[,1:7], y = hc[,8], nbest=1, method="Cp")

# Printing the 2 best models of each size, using the adjusted R squared criterion:

leaps::leaps(x = hc[,1:7], y = hc[,8], nbest=1, method="adjr2")

b <- regsubsets(hate_crimes_log ~ ., data=hc)
rs <- summary(b)
rs

par(mar=c(4,4,1,1))
par(mfrow=c(1,2))

plot(1:7, rs$cp, xlab="No of parameters", ylab="Cp Statistic")
abline(0,1)

plot(1:7, rs$adjr2, xlab="No of parameters", ylab="Adj R2")

res.sum_1 <- summary(b_1)
data.frame(
  Adj.R2 = which.max(res.sum_1$adjr2),
  CP = which.min(res.sum_1$cp),
  BIC = which.min(res.sum_1$bic)
)
```

Use ANOVA to compare the model with 2 covariates and the model with 3 covariates for the data excluding DC

```{r, message = FALSE, warning = FALSE}
# ANOVA
final_model_no_DC <- lm(hate_crimes_log ~ gini_index + perc_pop_hs, data = hate_crimes_df_no_DC )
summary(final_model_no_DC)

final_model_no_DC_unemploy <- lm(hate_crimes_log ~ gini_index + perc_pop_hs + unemployment, data = hate_crimes_df_no_DC)
summary(final_model_no_DC_unemploy)

anova(final_model_no_DC, final_model_no_DC_unemploy)

par(mfrow = c(2,2))
plot(final_model_no_DC)
plot(final_model_no_DC_unemploy)

```


Perform 5-fold Cross Validation looking at the Adjusted R^2 and the RMSE for the 2 covariates and 3 covariates models including DC:

2 Covariates
```{r validate the model with DC part 1}
final_model <- lm(hate_crimes_log ~ gini_index + perc_pop_hs, data = hate_crimes_df)
sm<-summary(final_model)
sm
sqrt(mean(sm$residuals^2))

set.seed(1)
data_train<-trainControl(method="cv", number=5)


model_caret<-train(hate_crimes_log ~ gini_index + perc_pop_hs,
                   data=hate_crimes_df,
                   trControl=data_train,
                   method='lm',
                   na.action=na.pass)
  
 
model_caret




model_caret$finalModel


model_caret$resample


sd(model_caret$resample$Rsquared)

```

Model adjusted R^2: 0.2541
Model RMSE: 0.5417445

CV adjusted R^2: 0.2943289
CV RMSE: 0.5948853


3 Covariates
```{r with Dc model validation part 2}
final_model_unemploy <- lm(hate_crimes_log ~ gini_index + perc_pop_hs + unemployment, data = hate_crimes_df)
sm<-summary(final_model_unemploy)
sm
sqrt(mean(sm$residuals^2))


set.seed(1)
data_train <- trainControl(method = "cv", number = 5)


model_caret<-train(hate_crimes_log ~ gini_index + perc_pop_hs + unemployment,
                   data=hate_crimes_df,
                   trControl=data_train,
                   method='lm',
                   na.action=na.pass)
  

model_caret


model_caret$finalModel

model_caret$resample


sd(model_caret$resample$Rsquared)
```

Model adjusted R^2: 0.2571 
Model RMSE: 0.5341956

CV adjusted R^2: 0.2783783
CV RMSE: 0.6038494




Perform 5-fold Cross Validation looking at the Adjusted R^2 and the RMSE for the 2 covariates and 3 covariates models excluding DC:

2 Covariates
```{r validate the model no DC}
final_model_no_DC <- lm(hate_crimes_log ~ gini_index + perc_pop_hs, data = hate_crimes_df_no_DC )
sm<-summary(final_model_no_DC)
sm
sqrt(mean(sm$residuals^2))


set.seed(1)
data_train<-trainControl(method="cv", number=5)


model_caret<-train(hate_crimes_log ~ gini_index + perc_pop_hs,
                   data=hate_crimes_df_no_DC,
                   trControl=data_train,
                   method='lm',
                   na.action=na.pass)
  

model_caret



model_caret$finalModel


model_caret$resample

sd(model_caret$resample$Rsquared)
```

Model adjusted R^2: 0.1185
Model RMSE: 0.5367246

CV adjusted R^2: 0.153031
CV MSE: 0.5554347


3 Covariates
```{r model validation no DC part 2}
final_model_no_DC_unemploy <- lm(hate_crimes_log ~ gini_index + perc_pop_hs + unemployment, data = hate_crimes_df_no_DC)
sm<-summary(final_model_no_DC_unemploy)
sm
sqrt(mean(sm$residuals^2))


set.seed(1)
data_train<-trainControl(method="cv", number=5)


model_caret<-train(hate_crimes_log ~ gini_index + perc_pop_hs +unemployment,
                   data=hate_crimes_df_no_DC,
                   trControl=data_train,
                   method='lm',
                   na.action=na.pass)
  

model_caret


model_caret$finalModel


model_caret$resample

sd(model_caret$resample$Rsquared)
```

Model adjusted R^2: 0.125
Model RMSE: 0.5281813

CV adjusted R^2: 0.1730294
CV RMSE: 0.560014


